{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fab3a4e8",
   "metadata": {
    "id": "YjDiF97VlnqF"
   },
   "source": [
    " <img src=\"https://www.nvidia.com/content/dam/en-zz/Solutions/about-nvidia/logo-and-brand/01-nvidia-logo-horiz-500x200-2c50-d@2x.png\" width=300>\n",
    " \n",
    "# 계산과학공학회 인공지능 겨울학교 2022\n",
    "# [KSCSE](http://www.cse.or.kr/) 2022  GPU Tutorial  @ High1\n",
    "# Day1 - Introducion to AI \n",
    "by Hyungon Ryu | NVAITC(NVIDIA AI Tech. Center)  Korea \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1402df25",
   "metadata": {
    "id": "OBf5KF3BLLfI"
   },
   "source": [
    "![](http://www.cse.or.kr/assets/img/logo_cse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54248e99",
   "metadata": {
    "id": "2Ov8cRpOdcjd"
   },
   "source": [
    "# Part4 - ResNet(Residual Network)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbf20f2",
   "metadata": {
    "id": "lvPXX0bWdiOI"
   },
   "source": [
    "Residual Networks\n",
    "We discovered that learning in a convolutional neural network is hierarchical: each increase in the number of layers results in more complex features being learned by the layers. But despite this, it is shown empirically that there is a maximum threshold for depth with a traditional CNN model.\n",
    "\n",
    "In a paper titled Deep Residual Learning for Image Recognition researchers from Microsoft pointed out the following:\n",
    "![](https://raw.githubusercontent.com/openhackathons-org/gpubootcamp/58e1329572bebc508ba7489a9f9415d7e0592ab8/hpc_ai/ai_science_cfd/English/python/jupyter_notebook/Intro_to_DL/images/resnet.PNG)\n",
    "\n",
    "The failure of the 56-layer CNN could be blamed on the optimization function, initialization of the network, or the famous vanishing/exploding gradient problem. Vanishing gradients are exceptionally easy to blame for this.\n",
    "\n",
    "So what is the vanishing gradient problem? When we do backpropagation, the gradients tend to get smaller and smaller as we keep on moving backwards in the network. This means that the neurons in the earlier layers learn very slowly as compared to the neurons in the later layers in the hierarchy. The earlier layers in the network are slowest to train.\n",
    "\n",
    "Earlier layers in the network are essential because they are responsible for learning and detecting the simple patterns and are actually the building blocks of our network. If they give improper and inaccurate results, we can't expect the next layers and the complete network to perform nicely and produce accurate results.\n",
    "\n",
    "The problem of training very deep networks has been alleviated with the introduction of a new neural network layer — the residual block.\n",
    "\n",
    "Optional - The Degradation Problem\n",
    "\n",
    "The degradation problem suggests that solvers might have difficulties in approximating identity mappings by multiple nonlinear layers without the residual learning reformulation.\n",
    "\n",
    "Let us consider network A having  layers and network B having  layers. Supposing that , if network A performs poorly relative to network B, one might argue that if network A had mapped an identity function for the first  layers, then it would have performed on par with network B. But it doesn't do that due to the vanishing gradient problem, so when we use residual networks, the network gets the input along with learning on the residual, and if the input function was appropriate, it could quickly change the weights of the residual function to be zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad214c8",
   "metadata": {
    "id": "K53YJbxEkWzc"
   },
   "source": [
    "\n",
    "## Residual Blocks\n",
    "In a residual block the activation of a layer is fast-forwarded to a deeper layer in the neural network. Residual blocks help in the flow of information from the initial layers to the final layers. This is done by the introduction of skip connections, as seen in the image below.\n",
    "\n",
    "Let us consider $H(x)$  as an underlying mapping to be fit by a few stacked layers (not necessarily the entire net), with  denoting the inputs to the first of these layers. If one hypothesizes that multiple nonlinear layers can asymptotically approximate complicated functions, then it is equivalent to hypothesize that they can asymptotically approximate the residual functions, i.e.,  (assuming that the input and output are of the same dimensions).\n",
    "\n",
    "So rather than expecting the stacked layers to approximate $H(x)$, we explicitly let these layers approximate a residual function.\n",
    "\n",
    "$F(x) = H(x) − x$.\n",
    "\n",
    "The original function thus becomes $F(x)+x$ .\n",
    "\n",
    "Although both models should be able to approximate the desired functions asymptotically, the ease of learning might be different. This reformulation is motivated by the counterintuitive phenomena about the degradation problem. As we discussed above, if the added layers can be constructed as identity mappings, a deeper model should have training error no greater than its shallow counterpart.\n",
    "![](https://raw.githubusercontent.com/openhackathons-org/gpubootcamp/58e1329572bebc508ba7489a9f9415d7e0592ab8/hpc_ai/ai_science_cfd/English/python/jupyter_notebook/Intro_to_DL/images/resblock.PNG)\n",
    "\n",
    "With this, increasing the number of layers improves accuracy. Here are some results from the paper:\n",
    "![](https://raw.githubusercontent.com/openhackathons-org/gpubootcamp/58e1329572bebc508ba7489a9f9415d7e0592ab8/hpc_ai/ai_science_cfd/English/python/jupyter_notebook/Intro_to_DL/images/stats.png)\n",
    "\n",
    "Now let us see how to write a residual block in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d126a5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9Vg2BbbFQIN",
    "outputId": "f50f51e9-0437-4f17-d2b4-33f1298c8cbf"
   },
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d89628",
   "metadata": {
    "id": "LJdE2HatFQIO"
   },
   "outputs": [],
   "source": [
    "# Let's Import the Dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e0056d",
   "metadata": {
    "id": "s9ntgFMBFQIO"
   },
   "outputs": [],
   "source": [
    "# Defining class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d4e530",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vrBI35OWFQIO",
    "outputId": "8505dd67-745b-4ad5-e9e8-a527d5fdab69"
   },
   "outputs": [],
   "source": [
    "# Printing the Size of our Dataset\n",
    "\n",
    "# Print array size of training dataset\n",
    "print(\"Size of Training Images: \" + str(train_images.shape))\n",
    "# Print array size of labels\n",
    "print(\"Size of Training Labels: \" + str(train_labels.shape))\n",
    "\n",
    "# Print array size of test dataset\n",
    "print(\"Size of Test Images: \" + str(test_images.shape))\n",
    "# Print array size of labels\n",
    "print(\"Size of Test Labels: \" + str(test_labels.shape))\n",
    "\n",
    "# Let's see how our outputs look\n",
    "print(\"Training Set Labels: \" + str(train_labels))\n",
    "# Data in the test dataset\n",
    "print(\"Test Set Labels: \" + str(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b73588",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "P2C12HlAFQIO",
    "outputId": "242cf6d3-ae24-4e8a-c0c8-dcab25440962"
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing \n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(train_images[0], cmap='gray')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e027a975",
   "metadata": {
    "id": "DnXMBJpjFQIO"
   },
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc12b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "id": "oVk7Ou6kFQIO",
    "outputId": "69220200-647b-46f0-bf97-cb0249c3953f"
   },
   "outputs": [],
   "source": [
    "# Let's print to verify whether the data is of the correct format.\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3068c3f",
   "metadata": {
    "id": "dVKyqfIgFQIO"
   },
   "outputs": [],
   "source": [
    "# Reshape input data from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "train_images = train_images.reshape(train_images.shape[0], w, h, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], w, h, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e4c9d",
   "metadata": {
    "id": "8iB-LW6AFQIO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d6eb6cb",
   "metadata": {
    "id": "aIe_B-l-fRjL"
   },
   "source": [
    "# Model\n",
    "Let's build a resnet model with Keras and train it.\n",
    "\n",
    "We will be using two kinds of residual blocks:\n",
    "\n",
    " - Identity Block\n",
    " - Convolution Block\n",
    "\n",
    " ## Identity Block\n",
    "In the identity block we have a skip connection with no change in input, paired with a standard set of convolutional layers.\n",
    "\n",
    "![](https://raw.githubusercontent.com/openhackathons-org/gpubootcamp/58e1329572bebc508ba7489a9f9415d7e0592ab8/hpc_ai/ai_science_cfd/English/python/jupyter_notebook/Intro_to_DL/images/identity.png)\n",
    "\n",
    "## Convolution Block\n",
    "The convolution block is very similar to the identity block, but there is a convolutional layer in the skip-connection path just to change the dimension such that the dimension of the input and output matches.\n",
    "![](https://raw.githubusercontent.com/openhackathons-org/gpubootcamp/58e1329572bebc508ba7489a9f9415d7e0592ab8/hpc_ai/ai_science_cfd/English/python/jupyter_notebook/Intro_to_DL/images/conv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bc7ab2",
   "metadata": {
    "id": "BpY6Hjo5f_yG"
   },
   "source": [
    "Let's start building the identity block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efd2a2f",
   "metadata": {
    "id": "28ifOtgVFQIP"
   },
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \n",
    "    # Defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # A path is a block of conv followed by batch normalization and activation\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path \n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713ca40f",
   "metadata": {
    "id": "e--4ckwPgB_t"
   },
   "source": [
    "Convolution Block\n",
    "Notice the only change we need to do is add a convolution and batch normalisation for the input data to match the output dimension.\n",
    "\n",
    "This can be done by adding the following lines :\n",
    "\n",
    "\n",
    "```\n",
    "##### SHORTCUT PATH #### \n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f0295",
   "metadata": {
    "id": "eaFvpj1NFQIP"
   },
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "\n",
    "    # Defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### \n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f668ce1e",
   "metadata": {
    "id": "ZXxM3a-3FQIP"
   },
   "outputs": [],
   "source": [
    "def ResNet(input_shape = (28, 28, 1), classes = 10):\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(shape=input_shape)\n",
    "\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (3, 3), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # AVGPOOL\n",
    "    X = AveragePooling2D(pool_size=(2,2), padding='same')(X)\n",
    "\n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaad5cb",
   "metadata": {
    "id": "PoSGRkfcFQIP"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n",
    "model = ResNet(input_shape = (28, 28, 1), classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18694fe",
   "metadata": {
    "id": "LB6AwnL_FQIP"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972779ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qsb20pJLFQIP",
    "outputId": "a958ea6e-691d-4e3b-dca0-5faf8485e2f5"
   },
   "outputs": [],
   "source": [
    "hist = model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs = 10, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c049da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "jyWyhEiFdw8y",
    "outputId": "8b51674d-122a-4e4d-e885-a5e8029037ee"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e03acc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "TvAvl1dxeAhv",
    "outputId": "2ba7a9e3-f463-4f7a-f64c-5168c3bcc02f"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['accuracy' ])\n",
    "plt.plot(hist.history[ 'val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262850cb",
   "metadata": {
    "id": "2_LEOu4pgTCr"
   },
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217bba0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tyhXw1WUFQIP",
    "outputId": "07f0bda4-25f5-43d6-ae88-4a6d71ee98c9"
   },
   "outputs": [],
   "source": [
    "# Making predictions from the test_images\n",
    "\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfabdab0",
   "metadata": {
    "id": "tq0zrdTeFQIP"
   },
   "outputs": [],
   "source": [
    "# Reshape input data from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "train_images = train_images.reshape(train_images.shape[0], w, h)\n",
    "test_images = test_images.reshape(test_images.shape[0], w, h)\n",
    "\n",
    "# Helper functions to plot images \n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array, true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c796d03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "u4k0Gf4oFQIQ",
    "outputId": "d8122a5d-4141-468f-9e65-6c4e2cff91d6"
   },
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc0a5d0",
   "metadata": {
    "id": "sW2iZmwngaqO"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d321b2a8",
   "metadata": {
    "id": "zDeXEFY-jepQ"
   },
   "source": [
    "Running all of our models for five epochs, and check the result and compare them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d311dab1",
   "metadata": {
    "id": "A4zjOLPSXJ5w"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bfed48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYmvBViwXKQV",
    "outputId": "5adeeebb-ce84-425c-bb17-5a601906d610"
   },
   "outputs": [],
   "source": [
    "# Let's Import the Dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1831366",
   "metadata": {
    "id": "umOzgJSUXO-r"
   },
   "outputs": [],
   "source": [
    "# Defining class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e5a95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0EMJ_ByYXUsG",
    "outputId": "a55eb737-58da-403a-b186-db342bec9ba0"
   },
   "outputs": [],
   "source": [
    "# Printing the Size of our Dataset\n",
    "\n",
    "# Print array size of training dataset\n",
    "print(\"Size of Training Images: \" + str(train_images.shape))\n",
    "# Print array size of labels\n",
    "print(\"Size of Training Labels: \" + str(train_labels.shape))\n",
    "\n",
    "# Print array size of test dataset\n",
    "print(\"Size of Test Images: \" + str(test_images.shape))\n",
    "# Print array size of labels\n",
    "print(\"Size of Test Labels: \" + str(test_labels.shape))\n",
    "\n",
    "# Let's see how our outputs look\n",
    "print(\"Training Set Labels: \" + str(train_labels))\n",
    "# Data in the test dataset\n",
    "print(\"Test Set Labels: \" + str(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cb2dc5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "cqQTtIsUXYlS",
    "outputId": "2ac1b255-6a22-4b27-84a6-fbe37d69eeee"
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing \n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(train_images[0], cmap='gray')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7eb516",
   "metadata": {
    "id": "MKGrbfw-XdcG"
   },
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df584c5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "id": "NGnIJhwwXik5",
    "outputId": "3656c33b-67bc-4dff-bcdd-7e97fc8441d5"
   },
   "outputs": [],
   "source": [
    "# Let's print to verify whether the data is of the correct format.\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c3f006",
   "metadata": {
    "id": "z5zxU2WlXoEn"
   },
   "outputs": [],
   "source": [
    "# Reshape input data from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "train_images = train_images.reshape(train_images.shape[0], w, h, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], w, h, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7906241c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ff5049f",
   "metadata": {},
   "source": [
    "# end of jupyter part4\n",
    "### Navigation  |[Part1-reg](part1_LR.ipynb) |  [Part2-MLP](part2_MLP.ipynb) |  [Part3-CNN](part3_CNN.ipynb) |  [Part4-ResNet](part4_resnet.ipynb) | [Part5-MLP Mixer](part5_Mixer.ipynb) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed7d358",
   "metadata": {},
   "source": [
    "<img src=\"https://www.nvidia.com/content/dam/en-zz/Solutions/about-nvidia/logo-and-brand/01-nvidia-logo-horiz-500x200-2c50-d@2x.png\" width=300>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
